{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "NSMC_Classification_charCNNEmbedding_LSTM.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPbWkll6MiCinJvq8A13rJp"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5P1TqyyOfKXr",
        "outputId": "6509f2cf-d6cc-4349-f256-b2e560df6c47"
      },
      "source": [
        "a = torch.randn([5,10,100])\n",
        "# batch x dim x seq\n",
        "conv = nn.Conv1d(10, 100,3)\n",
        "b = F.relu(conv(a))\n",
        "# batc x featuremap x (seqlen-1+filtersd)\n",
        "c = F.max_pool1d(b, b.shape[2])\n",
        "c.size()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:652: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
            "  return torch.max_pool1d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([5, 100, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m8X6TCb-6h8v",
        "outputId": "291529f9-6169-498b-ed7f-f732c65cbbbb"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "shyy79L76Tlt"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n3cnoF4_zk6r",
        "outputId": "46dfaaae-9b63-4294-ed38-f52fafa970ac"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7cJn0lKa6ePc",
        "outputId": "8d2fc1dd-6861-48a8-8913-b58148976a95"
      },
      "source": [
        "!git clone https://github.com/SOMJANG/Mecab-ko-for-Google-Colab.git\n",
        "%cd Mecab-ko-for-Google-Colab\n",
        "!bash install_mecab-ko_on_colab190912.sh"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'Mecab-ko-for-Google-Colab'...\n",
            "remote: Enumerating objects: 91, done.\u001b[K\n",
            "remote: Counting objects: 100% (91/91), done.\u001b[K\n",
            "remote: Compressing objects: 100% (85/85), done.\u001b[K\n",
            "remote: Total 91 (delta 43), reused 22 (delta 6), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (91/91), done.\n",
            "/content/Mecab-ko-for-Google-Colab\n",
            "Installing konlpy.....\n",
            "Collecting konlpy\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/85/0e/f385566fec837c0b83f216b2da65db9997b35dd675e107752005b7d392b1/konlpy-0.5.2-py2.py3-none-any.whl (19.4MB)\n",
            "\u001b[K     |████████████████████████████████| 19.4MB 6.0MB/s \n",
            "\u001b[?25hCollecting beautifulsoup4==4.6.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9e/d4/10f46e5cfac773e22707237bfcd51bbffeaf0a576b0a847ec7ab15bd7ace/beautifulsoup4-4.6.0-py3-none-any.whl (86kB)\n",
            "\u001b[K     |████████████████████████████████| 92kB 10.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.7/dist-packages (from konlpy) (1.19.5)\n",
            "Requirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (4.2.6)\n",
            "Requirement already satisfied: tweepy>=3.7.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (3.10.0)\n",
            "Collecting JPype1>=0.7.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/cd/a5/9781e2ef4ca92d09912c4794642c1653aea7607f473e156cf4d423a881a1/JPype1-1.2.1-cp37-cp37m-manylinux2010_x86_64.whl (457kB)\n",
            "\u001b[K     |████████████████████████████████| 460kB 34.8MB/s \n",
            "\u001b[?25hCollecting colorama\n",
            "  Downloading https://files.pythonhosted.org/packages/44/98/5b86278fbbf250d239ae0ecb724f8572af1c91f4a11edf4d36a206189440/colorama-0.4.4-py2.py3-none-any.whl\n",
            "Requirement already satisfied: requests[socks]>=2.11.1 in /usr/local/lib/python3.7/dist-packages (from tweepy>=3.7.0->konlpy) (2.23.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tweepy>=3.7.0->konlpy) (1.3.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tweepy>=3.7.0->konlpy) (1.15.0)\n",
            "Requirement already satisfied: typing-extensions; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from JPype1>=0.7.0->konlpy) (3.7.4.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.24.3)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6; extra == \"socks\" in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.7.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->tweepy>=3.7.0->konlpy) (3.1.0)\n",
            "Installing collected packages: beautifulsoup4, JPype1, colorama, konlpy\n",
            "  Found existing installation: beautifulsoup4 4.6.3\n",
            "    Uninstalling beautifulsoup4-4.6.3:\n",
            "      Successfully uninstalled beautifulsoup4-4.6.3\n",
            "Successfully installed JPype1-1.2.1 beautifulsoup4-4.6.0 colorama-0.4.4 konlpy-0.5.2\n",
            "Done\n",
            "Installing mecab-0.996-ko-0.9.2.tar.gz.....\n",
            "Downloading mecab-0.996-ko-0.9.2.tar.gz.......\n",
            "from https://bitbucket.org/eunjeon/mecab-ko/downloads/mecab-0.996-ko-0.9.2.tar.gz\n",
            "--2021-05-06 08:42:11--  https://bitbucket.org/eunjeon/mecab-ko/downloads/mecab-0.996-ko-0.9.2.tar.gz\n",
            "Resolving bitbucket.org (bitbucket.org)... 104.192.141.1, 2406:da00:ff00::22c2:513, 2406:da00:ff00::22cd:e0db, ...\n",
            "Connecting to bitbucket.org (bitbucket.org)|104.192.141.1|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://bbuseruploads.s3.amazonaws.com/eunjeon/mecab-ko/downloads/mecab-0.996-ko-0.9.2.tar.gz?Signature=3k2Tp2dbEwQ8JdhWMHt4jMCq%2BRI%3D&Expires=1620291910&AWSAccessKeyId=AKIA6KOSE3BNJRRFUUX6&versionId=null&response-content-disposition=attachment%3B%20filename%3D%22mecab-0.996-ko-0.9.2.tar.gz%22&response-content-encoding=None [following]\n",
            "--2021-05-06 08:42:12--  https://bbuseruploads.s3.amazonaws.com/eunjeon/mecab-ko/downloads/mecab-0.996-ko-0.9.2.tar.gz?Signature=3k2Tp2dbEwQ8JdhWMHt4jMCq%2BRI%3D&Expires=1620291910&AWSAccessKeyId=AKIA6KOSE3BNJRRFUUX6&versionId=null&response-content-disposition=attachment%3B%20filename%3D%22mecab-0.996-ko-0.9.2.tar.gz%22&response-content-encoding=None\n",
            "Resolving bbuseruploads.s3.amazonaws.com (bbuseruploads.s3.amazonaws.com)... 52.217.73.204\n",
            "Connecting to bbuseruploads.s3.amazonaws.com (bbuseruploads.s3.amazonaws.com)|52.217.73.204|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1414979 (1.3M) [application/x-tar]\n",
            "Saving to: ‘mecab-0.996-ko-0.9.2.tar.gz’\n",
            "\n",
            "mecab-0.996-ko-0.9. 100%[===================>]   1.35M  1.06MB/s    in 1.3s    \n",
            "\n",
            "2021-05-06 08:42:14 (1.06 MB/s) - ‘mecab-0.996-ko-0.9.2.tar.gz’ saved [1414979/1414979]\n",
            "\n",
            "Done\n",
            "Unpacking mecab-0.996-ko-0.9.2.tar.gz.......\n",
            "Done\n",
            "Change Directory to mecab-0.996-ko-0.9.2.......\n",
            "installing mecab-0.996-ko-0.9.2.tar.gz........\n",
            "configure\n",
            "make\n",
            "make check\n",
            "make install\n",
            "ldconfig\n",
            "Done\n",
            "Change Directory to /content\n",
            "Downloading mecab-ko-dic-2.1.1-20180720.tar.gz.......\n",
            "from https://bitbucket.org/eunjeon/mecab-ko-dic/downloads/mecab-ko-dic-2.1.1-20180720.tar.gz\n",
            "--2021-05-06 08:43:49--  https://bitbucket.org/eunjeon/mecab-ko-dic/downloads/mecab-ko-dic-2.1.1-20180720.tar.gz\n",
            "Resolving bitbucket.org (bitbucket.org)... 104.192.141.1, 2406:da00:ff00::22c2:513, 2406:da00:ff00::6b17:d1f5, ...\n",
            "Connecting to bitbucket.org (bitbucket.org)|104.192.141.1|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://bbuseruploads.s3.amazonaws.com/a4fcd83e-34f1-454e-a6ac-c242c7d434d3/downloads/b5a0c703-7b64-45ed-a2d7-180e962710b6/mecab-ko-dic-2.1.1-20180720.tar.gz?Signature=vuTnQtTgbfskHTWcHkAioyAjpCc%3D&Expires=1620292430&AWSAccessKeyId=AKIA6KOSE3BNJRRFUUX6&versionId=tzyxc1TtnZU_zEuaaQDGN4F76hPDpyFq&response-content-disposition=attachment%3B%20filename%3D%22mecab-ko-dic-2.1.1-20180720.tar.gz%22&response-content-encoding=None [following]\n",
            "--2021-05-06 08:43:50--  https://bbuseruploads.s3.amazonaws.com/a4fcd83e-34f1-454e-a6ac-c242c7d434d3/downloads/b5a0c703-7b64-45ed-a2d7-180e962710b6/mecab-ko-dic-2.1.1-20180720.tar.gz?Signature=vuTnQtTgbfskHTWcHkAioyAjpCc%3D&Expires=1620292430&AWSAccessKeyId=AKIA6KOSE3BNJRRFUUX6&versionId=tzyxc1TtnZU_zEuaaQDGN4F76hPDpyFq&response-content-disposition=attachment%3B%20filename%3D%22mecab-ko-dic-2.1.1-20180720.tar.gz%22&response-content-encoding=None\n",
            "Resolving bbuseruploads.s3.amazonaws.com (bbuseruploads.s3.amazonaws.com)... 52.217.40.180\n",
            "Connecting to bbuseruploads.s3.amazonaws.com (bbuseruploads.s3.amazonaws.com)|52.217.40.180|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 49775061 (47M) [application/x-tar]\n",
            "Saving to: ‘mecab-ko-dic-2.1.1-20180720.tar.gz’\n",
            "\n",
            "mecab-ko-dic-2.1.1- 100%[===================>]  47.47M  12.9MB/s    in 4.5s    \n",
            "\n",
            "2021-05-06 08:43:55 (10.4 MB/s) - ‘mecab-ko-dic-2.1.1-20180720.tar.gz’ saved [49775061/49775061]\n",
            "\n",
            "Done\n",
            "Unpacking  mecab-ko-dic-2.1.1-20180720.tar.gz.......\n",
            "Done\n",
            "Change Directory to mecab-ko-dic-2.1.1-20180720\n",
            "Done\n",
            "installing........\n",
            "configure\n",
            "make\n",
            "make install\n",
            "apt-get update\n",
            "apt-get upgrade\n",
            "apt install curl\n",
            "apt install git\n",
            "bash <(curl -s https://raw.githubusercontent.com/konlpy/konlpy/master/scripts/mecab.sh)\n",
            "Done\n",
            "Successfully Installed\n",
            "Now you can use Mecab\n",
            "from konlpy.tag import Mecab\n",
            "mecab = Mecab()\n",
            "사용자 사전 추가 방법 : https://bit.ly/3k0ZH53\n",
            "NameError: name 'Tagger' is not defined 오류 발생 시 런타임을 재실행 해주세요\n",
            "블로그에 해결 방법을 남겨주신 tana님 감사합니다.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I64YvthHBI_0"
      },
      "source": [
        "from torchtext.legacy import data\n",
        "from konlpy.tag import Mecab"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PYCwdiGnA03M",
        "outputId": "9a326060-67ff-4327-8ed4-7a5eee8a5c33"
      },
      "source": [
        "cd /content/drive/MyDrive/torch_example/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/torch_example\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ONSGndtPBMyr"
      },
      "source": [
        "tokenizer = Mecab()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dQg-1dMbLVsU",
        "outputId": "d7f46c0b-eb2e-4d90-e66e-54bdb86549f5"
      },
      "source": [
        "train = pd.read_csv(\"./data/nsmc/ratings_train.txt\", sep='\\t')\n",
        "test = pd.read_csv(\"./data/nsmc/ratings_test.txt\", sep='\\t')\n",
        "\n",
        "train = train.drop(columns=['id'])\n",
        "test = test.drop(columns=['id'])\n",
        "\n",
        "print(train.shape)\n",
        "print(test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(150000, 2)\n",
            "(50000, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_EL3Fhl5bDdU",
        "outputId": "1807215e-c041-482b-9503-ccb7fdd0c601"
      },
      "source": [
        "train_data = train.dropna() #말뭉치에서 nan 값을 제거함\n",
        "test_data = test.dropna()\n",
        "\n",
        "print(train_data.shape)\n",
        "print(test_data.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(149995, 2)\n",
            "(49997, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f7ATQyWmMMCF"
      },
      "source": [
        "train_data, valid_data = train_test_split(train_data, test_size=0.3, random_state=32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CWEE8eTSMhqh",
        "outputId": "054c8ba5-d49d-4224-a5b7-6115ea2cac0d"
      },
      "source": [
        "print(len(train_data))\n",
        "print(len(valid_data))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "104996\n",
            "44999\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NU4u-h4ZBO-6"
      },
      "source": [
        "TEXT = data.Field(sequential=True, use_vocab=True, tokenize=tokenizer.morphs, lower=False, batch_first=True, fix_length=20)\n",
        "LABEL = data.LabelField(dtype = torch.float) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8b4ymeVtNPl_"
      },
      "source": [
        "def convert_dataset(input_data, text, label):\n",
        "    list_of_example = [data.Example.fromlist(row.tolist(), fields=[('text', text), ('label', label)])  for _, row in input_data.iterrows()]\n",
        "    dataset = data.Dataset(examples=list_of_example, fields=[('text', text), ('label', label)])\n",
        "    return dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IR41A4m9OBJM"
      },
      "source": [
        "train_data = convert_dataset(train_data,TEXT,LABEL)\n",
        "valid_data = convert_dataset(valid_data, TEXT, LABEL)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e3CLzUr8DDkE"
      },
      "source": [
        "TEXT.build_vocab(train_data, max_size=10000)\n",
        "LABEL.build_vocab(train_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nFQaqoPnDLaE",
        "outputId": "6911c268-66b9-4e11-eea6-b2ef731ee5f7"
      },
      "source": [
        "print('단어 집합의 크기 : {}'.format(len(TEXT.vocab)))\n",
        "print('label 의 크기 : {}'.format(len(LABEL.vocab)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "단어 집합의 크기 : 10002\n",
            "label 의 크기 : 2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yeoY2_b4DS6E"
      },
      "source": [
        "10000개 단어 + \\<unk> + \\<pad> 토큰이 들어감\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kz5XeWKeEkwG",
        "outputId": "10d5bad1-e77d-48c2-a0ec-8840e97ea881"
      },
      "source": [
        "print(LABEL.vocab.stoi) #라벨 값이 "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "defaultdict(None, {0: 0, 1: 1})\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NQhMoHCg0ZmN"
      },
      "source": [
        "test_data = convert_dataset(test_data, TEXT, LABEL)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9gGUTpZ2DNvz"
      },
      "source": [
        "batch_size = 5\n",
        "train_iter, valid_iter, test_iter = data.Iterator.splits((train_data, valid_data, test_data), batch_size=batch_size, sort=False, device=device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Q8mve6nDg7_",
        "outputId": "74d53a30-1a2b-4738-bb0a-73d68e17f947"
      },
      "source": [
        "print('훈련 데이터의 미니 배치 수 : {}'.format(len(train_iter)))\n",
        "print('평가 데이터의 미니 배치 수 : {}'.format(len(valid_iter)))\n",
        "print('테스트 데이터의 미니 배치 수 : {}'.format(len(test_iter)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "훈련 데이터의 미니 배치 수 : 21000\n",
            "평가 데이터의 미니 배치 수 : 9000\n",
            "테스트 데이터의 미니 배치 수 : 10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PpDzDzvx0gMv"
      },
      "source": [
        "class ModelEmbedding(nn.Module):\n",
        "  def __init__(self, embed_size,n_filters, vocab):\n",
        "    super(self,ModelEmbedding).__init__()\n",
        "    # vocab : char 개수\n",
        "    self.embedding = nn.Embedding(vocab, embed_size, padding_idx=0)\n",
        "    self.conv = nn.ModuleList([nn.Conv1d(in_channels=embed_size, out_channels=n_filters, kernel_size=filters) for filters in [2,3,4])\n",
        "    self.dropout = nn.Dropout(p=0.3)\n",
        "  \n",
        "  def forward(self, x):\n",
        "    # x : batch x seq len(char)\n",
        "    embed = self.embedding(x)\n",
        "    #embed = batch x seq len x dim\n",
        "    embed = embed.permute(0,2,1)\n",
        "    #embed = batch x dim x seq len\n",
        "    conv_out = [F.relu(conv(embed)) for conv in self.conv]\n",
        "    # conv_out = batch x feature map x (seq len - filter_size[n] + 1)\n",
        "    # 어차피 300차원에 맞춰서 보내면 되서 상관없다고 생각이 듦\n",
        "    pooled = [F.max_pool1d(conv, conv.shape[2]).squeeze(2) for conv in conv_out]\n",
        "    # pooled = [batch x feature map] x filter cnt\n",
        "    output = torch.cat(pooled, dim=1)\n",
        "    return output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ktbu-EP9zIcl"
      },
      "source": [
        "class LSTM(nn.Module):\n",
        "  def __init__(self, input_dim, embedding_dim, hidden_dim, output_dim, dropout):\n",
        "    super(self, LSTM).__init__()\n",
        "    # vocab 개수 구해야함\n",
        "    self.embedding = ModelEmbedding(embed_size=50, n_filters=100, vocab=)\n",
        "    self.rnn = nn.LSTM(embedding_dim, hidden_dim, batch_first=True, dropout=dropout)\n",
        "    self.linear = nn.Linear(hidden_dim, output_dim)\n",
        "    self.dropout = nn.Dropout(p=dropout)\n",
        "  \n",
        "  def forward(self, x):\n",
        "    embeded = self.dropout(self.embedding(x))\n",
        "    # batch * seq len * dim\n",
        "    output, _ = self.rnn(embeded)\n",
        "    # output : batch * seq len * dim\n",
        "    output = self.linear(output[:, -1,:]) # seq의 가장 마지막 값을 넘김\n",
        "    return output\n",
        "\n",
        "  def _init_state(self, batch_size=1):\n",
        "    weight = next(self.parameters()).data\n",
        "    return weight.new(self.n_layers, batch_size, self.hidden_dim).zero_()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L15OceFfFBbi"
      },
      "source": [
        "class LSTM(nn.Module):\n",
        "  def __init__(self, input_dim, hidden_dim, output_dim, embedding_dim, dropout):\n",
        "    super().__init__()\n",
        "    self.embedding = nn.Embedding(input_dim, embedding_dim, padding_idx=0)\n",
        "    self.rnn = nn.LSTM(embedding_dim, hidden_dim, batch_first=True, dropout=dropout)\n",
        "    self.linear = nn.Linear(hidden_dim, output_dim)\n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "  \n",
        "  def forward(self, x):\n",
        "    embed = self.dropout(self.embedding(x))\n",
        "    output, _ = self.rnn(embed)\n",
        "    output = self.linear(output[:, -1, :])\n",
        "    return output\n",
        "  \n",
        "  def _init_state(self, batch_size=1):\n",
        "    weight = next(self.parameters()).data\n",
        "    return weight.new(self.n_layers, batch_size, self.hidden_dim).zero_()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hH0XYn65xqt5"
      },
      "source": [
        "def binary_accuracy(prediction, target):\n",
        "  '''\n",
        "from https://github.com/bentrevett/pytorch-sentiment-analysis/blob/master/1%20-%20Simple%20Sentiment%20Analysis.ipynb\n",
        "  '''\n",
        "  # round predictions to the closest integer (0 or 1)\n",
        "  rounded_preds = torch.round(torch.sigmoid(prediction))\n",
        "  \n",
        "  #convert into float for division\n",
        "  correct = (rounded_preds == target).float()\n",
        "\n",
        "  # rounded_preds = [ 1   0   0   1   1   1   0   1   1   1]\n",
        "  # targets       = [ 1   0   1   1   1   1   0   1   1   0]\n",
        "  # correct       = [1.0 1.0 0.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0]\n",
        "  acc = correct.sum() / len(correct)\n",
        "  return acc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9MgSjQr3sa5i"
      },
      "source": [
        "def train(model, train_iter):\n",
        "  model.train()\n",
        "\n",
        "  epoch_loss, epoch_acc = 0, 0\n",
        "  for batch in train_iter:\n",
        "    optimizer.zero_grad()\n",
        "    x, y = batch.text.to(device), batch.label.to(device)\n",
        "    y_hat = model(x).squeeze(1)\n",
        "\n",
        "    loss = criterion(y_hat, y)\n",
        "    acc = binary_accuracy(y_hat, y)\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    epoch_loss += loss.item()\n",
        "    epoch_acc += acc.item()\n",
        "\n",
        "  return epoch_loss / len(train_iter), epoch_acc / len(train_iter)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZkuKVVyCzTF8"
      },
      "source": [
        "def evaluate(model, valid_iter):\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "    eval_loss, eval_acc = 0, 0\n",
        "    for batch in valid_iter:\n",
        "      x,y = batch.text.to(device), batch.label.to(device)\n",
        "      y_hat = model(x).squeeze(1)\n",
        "      \n",
        "      loss = criterion(y_hat, y)\n",
        "      acc = binary_accuracy(y_hat, y)\n",
        "\n",
        "      eval_loss += loss.item()\n",
        "      eval_acc += acc.item()\n",
        "      \n",
        "  return eval_loss / len(valid_iter), eval_acc / len(valid_iter)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ss8RYLuN3QWN"
      },
      "source": [
        "def inference(model, test_iter):\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "    test_loss, test_acc = 0, 0\n",
        "    for batch in test_iter:\n",
        "      x, y = batch.text.to(device), batch.label.to(device)\n",
        "      y_hat = model(x).squeeze(1)\n",
        "\n",
        "      loss = criterion(y_hat, y)\n",
        "      acc = binary_accuracy(y_hat, y)\n",
        "      \n",
        "      test_loss += loss.item()\n",
        "      test_acc += acc.item()\n",
        "\n",
        "  return test_loss / len(test_iter), test_acc / len(test_iter)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ilZJ-N2M1dcD",
        "outputId": "daaf4b44-0d0f-4078-eee4-6fc1fc15da0a"
      },
      "source": [
        "model = LSTM(len(TEXT.vocab), 128, len(LABEL.vocab)-1, 300, 0.2)\n",
        "model.to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "criterion.to(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:63: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
            "  \"num_layers={}\".format(dropout, num_layers))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BCEWithLogitsLoss()"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DShy6pep2BIO",
        "outputId": "fd827a0c-3d92-4f59-c22f-650e057f3bb2"
      },
      "source": [
        "best_val_loss = float('inf')\n",
        "for _epoch in range(1,6): # 5 epoch\n",
        "  train_loss, train_acc = train(model, train_iter)\n",
        "  valid_loss, valid_acc = evaluate(model, valid_iter)\n",
        "  print(\"[Epoch: %d] train loss : %5.2f | train accuracy : %5.2f\" % (_epoch, train_loss, train_acc))\n",
        "  print(\"[Epoch: %d] val loss : %5.2f | val accuracy : %5.2f\" % (_epoch, valid_loss, valid_acc))\n",
        "\n",
        "    # 검증 오차가 가장 적은 최적의 모델을 저장\n",
        "  if valid_loss < best_val_loss:\n",
        "    best_val_loss = valid_loss"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Epoch: 1] train loss :  0.42 | train accuracy :  0.80\n",
            "[Epoch: 1] val loss :  0.36 | val accuracy :  0.84\n",
            "[Epoch: 2] train loss :  0.33 | train accuracy :  0.86\n",
            "[Epoch: 2] val loss :  0.35 | val accuracy :  0.85\n",
            "[Epoch: 3] train loss :  0.30 | train accuracy :  0.87\n",
            "[Epoch: 3] val loss :  0.35 | val accuracy :  0.85\n",
            "[Epoch: 4] train loss :  0.28 | train accuracy :  0.88\n",
            "[Epoch: 4] val loss :  0.36 | val accuracy :  0.85\n",
            "[Epoch: 5] train loss :  0.27 | train accuracy :  0.89\n",
            "[Epoch: 5] val loss :  0.36 | val accuracy :  0.85\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZP8Lqf7n5CgO"
      },
      "source": [
        "test_loss, test_acc = inference(model, test_iter)\n",
        "print('Test Loss: %5.2f | Test Acc: %5.2f '%(test_loss, test_acc*100))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aFeqcwhpeIoV"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0yqmiLYRgVfO"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}