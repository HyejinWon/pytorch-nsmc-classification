{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NSMC_Classification_pretrainedEmbedding.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m8X6TCb-6h8v",
        "outputId": "70e18253-40b5-4a80-ecb9-b59b9e779222"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "shyy79L76Tlt"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n3cnoF4_zk6r",
        "outputId": "77ab3efb-edae-4b8d-c502-e8e719113fdd"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cpu\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7cJn0lKa6ePc",
        "outputId": "792d8073-7cc3-45c6-c752-f1c4973f617d"
      },
      "source": [
        "!git clone https://github.com/SOMJANG/Mecab-ko-for-Google-Colab.git\n",
        "%cd Mecab-ko-for-Google-Colab\n",
        "!bash install_mecab-ko_on_colab190912.sh"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fatal: destination path 'Mecab-ko-for-Google-Colab' already exists and is not an empty directory.\n",
            "/content/drive/My Drive/torch_example/Mecab-ko-for-Google-Colab\n",
            "Installing konlpy.....\n",
            "Collecting konlpy\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/85/0e/f385566fec837c0b83f216b2da65db9997b35dd675e107752005b7d392b1/konlpy-0.5.2-py2.py3-none-any.whl (19.4MB)\n",
            "\u001b[K     |████████████████████████████████| 19.4MB 1.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: tweepy>=3.7.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (3.10.0)\n",
            "Requirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.7/dist-packages (from konlpy) (1.19.5)\n",
            "Collecting colorama\n",
            "  Downloading https://files.pythonhosted.org/packages/44/98/5b86278fbbf250d239ae0ecb724f8572af1c91f4a11edf4d36a206189440/colorama-0.4.4-py2.py3-none-any.whl\n",
            "Requirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (4.2.6)\n",
            "Collecting JPype1>=0.7.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/cd/a5/9781e2ef4ca92d09912c4794642c1653aea7607f473e156cf4d423a881a1/JPype1-1.2.1-cp37-cp37m-manylinux2010_x86_64.whl (457kB)\n",
            "\u001b[K     |████████████████████████████████| 460kB 43.2MB/s \n",
            "\u001b[?25hCollecting beautifulsoup4==4.6.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9e/d4/10f46e5cfac773e22707237bfcd51bbffeaf0a576b0a847ec7ab15bd7ace/beautifulsoup4-4.6.0-py3-none-any.whl (86kB)\n",
            "\u001b[K     |████████████████████████████████| 92kB 8.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests[socks]>=2.11.1 in /usr/local/lib/python3.7/dist-packages (from tweepy>=3.7.0->konlpy) (2.23.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tweepy>=3.7.0->konlpy) (1.15.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tweepy>=3.7.0->konlpy) (1.3.0)\n",
            "Requirement already satisfied: typing-extensions; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from JPype1>=0.7.0->konlpy) (3.7.4.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (3.0.4)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6; extra == \"socks\" in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.7.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->tweepy>=3.7.0->konlpy) (3.1.0)\n",
            "Installing collected packages: colorama, JPype1, beautifulsoup4, konlpy\n",
            "  Found existing installation: beautifulsoup4 4.6.3\n",
            "    Uninstalling beautifulsoup4-4.6.3:\n",
            "      Successfully uninstalled beautifulsoup4-4.6.3\n",
            "Successfully installed JPype1-1.2.1 beautifulsoup4-4.6.0 colorama-0.4.4 konlpy-0.5.2\n",
            "Done\n",
            "Installing mecab-0.996-ko-0.9.2.tar.gz.....\n",
            "Downloading mecab-0.996-ko-0.9.2.tar.gz.......\n",
            "from https://bitbucket.org/eunjeon/mecab-ko/downloads/mecab-0.996-ko-0.9.2.tar.gz\n",
            "--2021-05-07 10:53:52--  https://bitbucket.org/eunjeon/mecab-ko/downloads/mecab-0.996-ko-0.9.2.tar.gz\n",
            "Resolving bitbucket.org (bitbucket.org)... 104.192.141.1, 2406:da00:ff00::22c2:513, 2406:da00:ff00::22cd:e0db, ...\n",
            "Connecting to bitbucket.org (bitbucket.org)|104.192.141.1|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://bbuseruploads.s3.amazonaws.com/eunjeon/mecab-ko/downloads/mecab-0.996-ko-0.9.2.tar.gz?Signature=5Prn991XKLzIMWVw8qKfsV1A35Y%3D&Expires=1620386632&AWSAccessKeyId=AKIA6KOSE3BNJRRFUUX6&versionId=null&response-content-disposition=attachment%3B%20filename%3D%22mecab-0.996-ko-0.9.2.tar.gz%22&response-content-encoding=None [following]\n",
            "--2021-05-07 10:53:52--  https://bbuseruploads.s3.amazonaws.com/eunjeon/mecab-ko/downloads/mecab-0.996-ko-0.9.2.tar.gz?Signature=5Prn991XKLzIMWVw8qKfsV1A35Y%3D&Expires=1620386632&AWSAccessKeyId=AKIA6KOSE3BNJRRFUUX6&versionId=null&response-content-disposition=attachment%3B%20filename%3D%22mecab-0.996-ko-0.9.2.tar.gz%22&response-content-encoding=None\n",
            "Resolving bbuseruploads.s3.amazonaws.com (bbuseruploads.s3.amazonaws.com)... 52.217.171.225\n",
            "Connecting to bbuseruploads.s3.amazonaws.com (bbuseruploads.s3.amazonaws.com)|52.217.171.225|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1414979 (1.3M) [application/x-tar]\n",
            "Saving to: ‘mecab-0.996-ko-0.9.2.tar.gz’\n",
            "\n",
            "mecab-0.996-ko-0.9. 100%[===================>]   1.35M  1.08MB/s    in 1.3s    \n",
            "\n",
            "2021-05-07 10:53:55 (1.08 MB/s) - ‘mecab-0.996-ko-0.9.2.tar.gz’ saved [1414979/1414979]\n",
            "\n",
            "Done\n",
            "Unpacking mecab-0.996-ko-0.9.2.tar.gz.......\n",
            "Done\n",
            "Change Directory to mecab-0.996-ko-0.9.2.......\n",
            "installing mecab-0.996-ko-0.9.2.tar.gz........\n",
            "configure\n",
            "make\n",
            "make check\n",
            "make install\n",
            "ldconfig\n",
            "Done\n",
            "Change Directory to /content\n",
            "Downloading mecab-ko-dic-2.1.1-20180720.tar.gz.......\n",
            "from https://bitbucket.org/eunjeon/mecab-ko-dic/downloads/mecab-ko-dic-2.1.1-20180720.tar.gz\n",
            "--2021-05-07 10:55:31--  https://bitbucket.org/eunjeon/mecab-ko-dic/downloads/mecab-ko-dic-2.1.1-20180720.tar.gz\n",
            "Resolving bitbucket.org (bitbucket.org)... 104.192.141.1, 2406:da00:ff00::22c2:513, 2406:da00:ff00::6b17:d1f5, ...\n",
            "Connecting to bitbucket.org (bitbucket.org)|104.192.141.1|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://bbuseruploads.s3.amazonaws.com/a4fcd83e-34f1-454e-a6ac-c242c7d434d3/downloads/b5a0c703-7b64-45ed-a2d7-180e962710b6/mecab-ko-dic-2.1.1-20180720.tar.gz?Signature=neD4GZakb2y04muo91IMc%2FTSXbE%3D&Expires=1620386732&AWSAccessKeyId=AKIA6KOSE3BNJRRFUUX6&versionId=tzyxc1TtnZU_zEuaaQDGN4F76hPDpyFq&response-content-disposition=attachment%3B%20filename%3D%22mecab-ko-dic-2.1.1-20180720.tar.gz%22&response-content-encoding=None [following]\n",
            "--2021-05-07 10:55:32--  https://bbuseruploads.s3.amazonaws.com/a4fcd83e-34f1-454e-a6ac-c242c7d434d3/downloads/b5a0c703-7b64-45ed-a2d7-180e962710b6/mecab-ko-dic-2.1.1-20180720.tar.gz?Signature=neD4GZakb2y04muo91IMc%2FTSXbE%3D&Expires=1620386732&AWSAccessKeyId=AKIA6KOSE3BNJRRFUUX6&versionId=tzyxc1TtnZU_zEuaaQDGN4F76hPDpyFq&response-content-disposition=attachment%3B%20filename%3D%22mecab-ko-dic-2.1.1-20180720.tar.gz%22&response-content-encoding=None\n",
            "Resolving bbuseruploads.s3.amazonaws.com (bbuseruploads.s3.amazonaws.com)... 52.217.69.20\n",
            "Connecting to bbuseruploads.s3.amazonaws.com (bbuseruploads.s3.amazonaws.com)|52.217.69.20|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 49775061 (47M) [application/x-tar]\n",
            "Saving to: ‘mecab-ko-dic-2.1.1-20180720.tar.gz’\n",
            "\n",
            "mecab-ko-dic-2.1.1- 100%[===================>]  47.47M  13.3MB/s    in 4.3s    \n",
            "\n",
            "2021-05-07 10:55:37 (11.1 MB/s) - ‘mecab-ko-dic-2.1.1-20180720.tar.gz’ saved [49775061/49775061]\n",
            "\n",
            "Done\n",
            "Unpacking  mecab-ko-dic-2.1.1-20180720.tar.gz.......\n",
            "Done\n",
            "Change Directory to mecab-ko-dic-2.1.1-20180720\n",
            "Done\n",
            "installing........\n",
            "configure\n",
            "make\n",
            "make install\n",
            "apt-get update\n",
            "apt-get upgrade\n",
            "apt install curl\n",
            "apt install git\n",
            "bash <(curl -s https://raw.githubusercontent.com/konlpy/konlpy/master/scripts/mecab.sh)\n",
            "Done\n",
            "Successfully Installed\n",
            "Now you can use Mecab\n",
            "from konlpy.tag import Mecab\n",
            "mecab = Mecab()\n",
            "사용자 사전 추가 방법 : https://bit.ly/3k0ZH53\n",
            "NameError: name 'Tagger' is not defined 오류 발생 시 런타임을 재실행 해주세요\n",
            "블로그에 해결 방법을 남겨주신 tana님 감사합니다.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I64YvthHBI_0"
      },
      "source": [
        "from torchtext.legacy import data\n",
        "from konlpy.tag import Mecab"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PYCwdiGnA03M",
        "outputId": "bcfeeb4f-623a-4acc-81c4-b544df64b8f0"
      },
      "source": [
        "cd /content/drive/MyDrive/torch_example/"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/torch_example\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ONSGndtPBMyr"
      },
      "source": [
        "tokenizer = Mecab()"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dQg-1dMbLVsU",
        "outputId": "d6fc7427-e45d-4c4c-9cf8-51e53bfd90f5"
      },
      "source": [
        "train = pd.read_csv(\"./data/nsmc/ratings_train.txt\", sep='\\t')\n",
        "test = pd.read_csv(\"./data/nsmc/ratings_test.txt\", sep='\\t')\n",
        "\n",
        "train = train.drop(columns=['id'])\n",
        "test = test.drop(columns=['id'])\n",
        "\n",
        "print(train.shape)\n",
        "print(test.shape)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(150000, 2)\n",
            "(50000, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_EL3Fhl5bDdU",
        "outputId": "5534d022-c151-46a3-a3ac-a1436ebe949b"
      },
      "source": [
        "train_data = train.dropna() #말뭉치에서 nan 값을 제거함\n",
        "test_data = test.dropna()\n",
        "\n",
        "print(train_data.shape)\n",
        "print(test_data.shape)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(149995, 2)\n",
            "(49997, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f7ATQyWmMMCF"
      },
      "source": [
        "train_data, valid_data = train_test_split(train_data, test_size=0.3, random_state=32)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CWEE8eTSMhqh",
        "outputId": "4cf8c06f-5c03-453f-881e-de65878658f4"
      },
      "source": [
        "print(len(train_data))\n",
        "print(len(valid_data))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "104996\n",
            "44999\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NU4u-h4ZBO-6"
      },
      "source": [
        "TEXT = data.Field(sequential=True, use_vocab=True, tokenize=tokenizer.morphs, lower=False, batch_first=True, fix_length=20)\n",
        "LABEL = data.LabelField(dtype = torch.float) "
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8b4ymeVtNPl_"
      },
      "source": [
        "def convert_dataset(input_data, text, label):\n",
        "    list_of_example = [data.Example.fromlist(row.tolist(), fields=[('text', text), ('label', label)])  for _, row in input_data.iterrows()]\n",
        "    dataset = data.Dataset(examples=list_of_example, fields=[('text', text), ('label', label)])\n",
        "    return dataset"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IR41A4m9OBJM"
      },
      "source": [
        "train_data = convert_dataset(train_data,TEXT,LABEL)\n",
        "valid_data = convert_dataset(valid_data, TEXT, LABEL)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bUFofwYmqJz8"
      },
      "source": [
        "load pretrained embedding vector and used!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jqojOMvwqQO2"
      },
      "source": [
        "The pretrained embedding vector based on news paper with tokenized by Mecab. Dimension is 200, Iteration is 100, corpus size is 1.5GB"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ShlfsZ5LUnzG",
        "outputId": "3de58789-bcef-414b-95fc-430d2c5de5b2"
      },
      "source": [
        "import torchtext.vocab as vocab\n",
        "my_embedding = vocab.Vectors(name='./vector/mecab_200_vec.txt', cache='my_embedding', unk_init=torch.Tensor.normal_)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 0/181670 [00:00<?, ?it/s]Skipping token b'181670' with 1-dimensional vector [b'200']; likely a header\n",
            " 99%|█████████▉| 180614/181670 [00:14<00:00, 11987.35it/s]"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e3CLzUr8DDkE"
      },
      "source": [
        "TEXT.build_vocab(train_data, max_size=10000, vectors=my_embedding)\n",
        "LABEL.build_vocab(train_data)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nFQaqoPnDLaE",
        "outputId": "1a009801-5d1c-48b1-f6be-63733ad3ee59"
      },
      "source": [
        "print('단어 집합의 크기 : {}'.format(len(TEXT.vocab)))\n",
        "print('label 의 크기 : {}'.format(len(LABEL.vocab)))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "단어 집합의 크기 : 10002\n",
            "label 의 크기 : 2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yeoY2_b4DS6E"
      },
      "source": [
        "10000개 단어 + \\<unk> + \\<pad> 토큰이 들어감\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kz5XeWKeEkwG",
        "outputId": "2e18b857-caae-4293-e64e-4f9cc261b6fc"
      },
      "source": [
        "print(LABEL.vocab.stoi) #라벨 값이 "
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "defaultdict(None, {0: 0, 1: 1})\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C2c4ID1MgUfU",
        "outputId": "b849bb64-7760-487b-8865-3d3b0abc5642"
      },
      "source": [
        "print(TEXT.vocab.vectors.shape) #벡터 차원200, 토큰 개수10002개"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([10002, 200])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NQhMoHCg0ZmN"
      },
      "source": [
        "test_data = convert_dataset(test_data, TEXT, LABEL)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9gGUTpZ2DNvz"
      },
      "source": [
        "batch_size = 5\n",
        "train_iter, valid_iter, test_iter = data.Iterator.splits((train_data, valid_data, test_data), batch_size=batch_size, sort=False, device=device)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Q8mve6nDg7_",
        "outputId": "0d1da759-a3c1-4815-b466-38c3b97e0f98"
      },
      "source": [
        "print('훈련 데이터의 미니 배치 수 : {}'.format(len(train_iter)))\n",
        "print('평가 데이터의 미니 배치 수 : {}'.format(len(valid_iter)))\n",
        "print('테스트 데이터의 미니 배치 수 : {}'.format(len(test_iter)))"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "훈련 데이터의 미니 배치 수 : 21000\n",
            "평가 데이터의 미니 배치 수 : 9000\n",
            "테스트 데이터의 미니 배치 수 : 10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kMFDbXHTXA03"
      },
      "source": [
        ""
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L15OceFfFBbi"
      },
      "source": [
        "class LSTM(nn.Module):\n",
        "  def __init__(self, input_dim, hidden_dim, output_dim, embedding_dim, dropout):\n",
        "    super().__init__()\n",
        "    # pretrained embedding vector with Freezing\n",
        "    self.embedding = nn.Embedding.from_pretrained(TEXT.vocab.vectors)\n",
        "\n",
        "    # if you want use unFreezing pretrained embedding write freezing option like under line.\n",
        "    # self.embedding = nn.Embedding.from_pretrained(TEXT.vocab.vector, freeze=False)\n",
        "    \n",
        "    self.rnn = nn.LSTM(embedding_dim, hidden_dim, batch_first=True, dropout=dropout)\n",
        "    self.linear = nn.Linear(hidden_dim, output_dim)\n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "  \n",
        "  def forward(self, x):\n",
        "    embed = self.dropout(self.embedding(x))\n",
        "    output, _ = self.rnn(embed)\n",
        "    output = self.linear(output[:, -1, :])\n",
        "    return output\n",
        "  \n",
        "  def _init_state(self, batch_size=1):\n",
        "    weight = next(self.parameters()).data\n",
        "    return weight.new(self.n_layers, batch_size, self.hidden_dim).zero_()"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hH0XYn65xqt5"
      },
      "source": [
        "def binary_accuracy(prediction, target):\n",
        "  '''\n",
        "from https://github.com/bentrevett/pytorch-sentiment-analysis/blob/master/1%20-%20Simple%20Sentiment%20Analysis.ipynb\n",
        "  '''\n",
        "  # round predictions to the closest integer (0 or 1)\n",
        "  rounded_preds = torch.round(torch.sigmoid(prediction))\n",
        "  \n",
        "  #convert into float for division\n",
        "  correct = (rounded_preds == target).float()\n",
        "\n",
        "  # rounded_preds = [ 1   0   0   1   1   1   0   1   1   1]\n",
        "  # targets       = [ 1   0   1   1   1   1   0   1   1   0]\n",
        "  # correct       = [1.0 1.0 0.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0]\n",
        "  acc = correct.sum() / len(correct)\n",
        "  return acc"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9MgSjQr3sa5i"
      },
      "source": [
        "def train(model, train_iter):\n",
        "  model.train()\n",
        "\n",
        "  epoch_loss, epoch_acc = 0, 0\n",
        "  for batch in train_iter:\n",
        "    optimizer.zero_grad()\n",
        "    x, y = batch.text.to(device), batch.label.to(device)\n",
        "    y_hat = model(x).squeeze(1)\n",
        "\n",
        "    loss = criterion(y_hat, y)\n",
        "    acc = binary_accuracy(y_hat, y)\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    epoch_loss += loss.item()\n",
        "    epoch_acc += acc.item()\n",
        "\n",
        "  return epoch_loss / len(train_iter), epoch_acc / len(train_iter)\n"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZkuKVVyCzTF8"
      },
      "source": [
        "def evaluate(model, valid_iter):\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "    eval_loss, eval_acc = 0, 0\n",
        "    for batch in valid_iter:\n",
        "      x,y = batch.text.to(device), batch.label.to(device)\n",
        "      y_hat = model(x).squeeze(1)\n",
        "      \n",
        "      loss = criterion(y_hat, y)\n",
        "      acc = binary_accuracy(y_hat, y)\n",
        "\n",
        "      eval_loss += loss.item()\n",
        "      eval_acc += acc.item()\n",
        "      \n",
        "  return eval_loss / len(valid_iter), eval_acc / len(valid_iter)"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ss8RYLuN3QWN"
      },
      "source": [
        "def inference(model, test_iter):\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "    test_loss, test_acc = 0, 0\n",
        "    for batch in test_iter:\n",
        "      x, y = batch.text.to(device), batch.label.to(device)\n",
        "      y_hat = model(x).squeeze(1)\n",
        "\n",
        "      loss = criterion(y_hat, y)\n",
        "      acc = binary_accuracy(y_hat, y)\n",
        "      \n",
        "      test_loss += loss.item()\n",
        "      test_acc += acc.item()\n",
        "\n",
        "  return test_loss / len(test_iter), test_acc / len(test_iter)"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ilZJ-N2M1dcD",
        "outputId": "d999be0b-0fab-46ce-fba9-c433b1f840af"
      },
      "source": [
        "model = LSTM(len(TEXT.vocab), 128, len(LABEL.vocab)-1, 200, 0.2)\n",
        "model.to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "criterion.to(device)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/modules/rnn.py:63: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
            "  \"num_layers={}\".format(dropout, num_layers))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BCEWithLogitsLoss()"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DShy6pep2BIO",
        "outputId": "77651265-9733-4292-b82a-8c06a3b9a241"
      },
      "source": [
        "best_val_loss = float('inf')\n",
        "for _epoch in range(1,6): # 5 epoch\n",
        "  train_loss, train_acc = train(model, train_iter)\n",
        "  valid_loss, valid_acc = evaluate(model, valid_iter)\n",
        "  print(\"[Epoch: %d] train loss : %5.2f | train accuracy : %5.2f\" % (_epoch, train_loss, train_acc))\n",
        "  print(\"[Epoch: %d] val loss : %5.2f | val accuracy : %5.2f\" % (_epoch, valid_loss, valid_acc))\n",
        "\n",
        "    # 검증 오차가 가장 적은 최적의 모델을 저장\n",
        "  if valid_loss < best_val_loss:\n",
        "    best_val_loss = valid_loss\n",
        "    torch.save(model.state_dict(),'tut1-model.pt')"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Epoch: 1] train loss :  0.45 | train accuracy :  0.78\n",
            "[Epoch: 1] val loss :  0.38 | val accuracy :  0.83\n",
            "[Epoch: 2] train loss :  0.37 | train accuracy :  0.83\n",
            "[Epoch: 2] val loss :  0.35 | val accuracy :  0.84\n",
            "[Epoch: 3] train loss :  0.34 | train accuracy :  0.85\n",
            "[Epoch: 3] val loss :  0.35 | val accuracy :  0.85\n",
            "[Epoch: 4] train loss :  0.32 | train accuracy :  0.86\n",
            "[Epoch: 4] val loss :  0.34 | val accuracy :  0.85\n",
            "[Epoch: 5] train loss :  0.30 | train accuracy :  0.87\n",
            "[Epoch: 5] val loss :  0.35 | val accuracy :  0.85\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZP8Lqf7n5CgO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7ca0c005-5057-478d-8902-2dc99769fce8"
      },
      "source": [
        "test_loss, test_acc = inference(model, test_iter)\n",
        "print('Test Loss: %5.2f | Test Acc: %5.2f '%(test_loss, test_acc*100))"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Loss:  0.35 | Test Acc: 84.76 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aFeqcwhpeIoV"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HtSKEKTHpjrf"
      },
      "source": [
        "check word vector in pretrained embedding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dKRy4d3bpuAB",
        "outputId": "3ebf76d3-7f51-4b84-f37e-c78e772a4798"
      },
      "source": [
        "TEXT.vocab.vectors[TEXT.vocab.stoi['사과']]"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-1.8117e-02, -1.3958e-01,  2.3630e-01, -2.7158e-02,  2.0225e-01,\n",
              "        -8.9995e-02,  5.0562e-01, -5.4435e-01, -7.8093e-02, -1.8677e-01,\n",
              "        -2.1117e-01, -1.3257e-01, -6.2217e-02, -1.2082e-01,  1.5681e-01,\n",
              "        -3.7383e-01,  6.7868e-02,  8.6042e-01,  3.3801e-01,  8.7876e-02,\n",
              "        -6.5293e-01,  5.4694e-02,  8.2626e-02,  2.8089e-01, -1.3018e-01,\n",
              "        -3.1103e-02, -5.2466e-01,  2.0239e-01,  5.2359e-01,  2.1270e-01,\n",
              "        -1.1202e-01, -1.4046e-01,  4.2592e-01, -3.5816e-01,  3.2228e-01,\n",
              "        -2.0581e-02,  8.8021e-02, -7.8883e-02,  5.4781e-01, -4.8231e-01,\n",
              "        -1.1365e-01,  3.7111e-01,  3.4829e-01, -1.0040e-01,  3.0546e-01,\n",
              "        -1.1306e-01, -1.1919e-01,  1.4974e-01,  2.5124e-01, -3.1577e-01,\n",
              "        -3.2229e-01, -2.5127e-01,  3.9752e-01,  1.5526e-01,  6.0606e-02,\n",
              "        -1.5560e-03, -5.4798e-02,  3.5820e-01,  4.6365e-01, -3.5335e-01,\n",
              "         9.4730e-02,  4.6722e-01, -4.6081e-02, -1.7977e-01, -5.2109e-01,\n",
              "        -8.9270e-03, -1.5695e-01,  4.0390e-03,  6.9196e-02,  3.9014e-01,\n",
              "        -6.3749e-01,  1.0001e-01, -1.7741e-01, -1.1537e-01, -3.6706e-02,\n",
              "        -3.2356e-02, -4.1356e-01,  1.9806e-01,  7.7503e-02, -7.9531e-02,\n",
              "         3.4987e-01,  1.0729e-01,  2.4680e-01,  1.2054e-01,  2.9800e-01,\n",
              "         6.5893e-01,  3.1914e-01, -1.3038e-01,  1.2901e-01, -3.8974e-01,\n",
              "         6.6696e-01,  7.5830e-03,  5.9643e-02,  2.7772e-01, -1.7336e-01,\n",
              "         4.2681e-01,  2.5871e-01, -3.2521e-01, -1.5071e-01,  3.0555e-01,\n",
              "        -1.1788e-02, -1.6607e-01,  1.1204e-02,  2.2154e-01,  1.6176e-01,\n",
              "         1.4774e-01,  2.5413e-01,  5.1798e-01, -6.8483e-02, -9.1790e-03,\n",
              "         1.2744e-01,  1.2219e-01,  1.7747e-01, -4.8814e-02, -1.6868e-01,\n",
              "         4.1198e-02, -3.9460e-03,  4.0383e-01, -7.0779e-02, -2.4211e-01,\n",
              "         3.6618e-01, -3.0690e-01,  1.8028e-01,  2.3648e-01, -4.1147e-02,\n",
              "        -5.0092e-02,  4.6485e-01,  1.2277e-01, -4.8700e-01, -6.8530e-03,\n",
              "        -3.7373e-01,  3.1574e-01, -8.0223e-02,  2.9134e-01, -4.3199e-01,\n",
              "        -2.7902e-01,  2.2251e-02,  2.1859e-01, -1.3225e-01, -3.5055e-01,\n",
              "        -3.3530e-02,  5.8837e-02,  1.5853e-01, -3.9439e-01,  7.9530e-02,\n",
              "         3.1075e-01, -3.0202e-01, -1.8458e-01, -4.3419e-01,  3.4988e-01,\n",
              "        -6.3668e-01,  2.6100e-04,  5.4109e-01,  7.3577e-02, -2.1337e-01,\n",
              "         1.5991e-01,  1.6260e-01, -3.5560e-01, -9.0312e-02, -1.9961e-01,\n",
              "        -1.5198e-01,  1.0322e-01,  5.2454e-01, -2.5143e-01, -1.2456e-01,\n",
              "        -3.5718e-01, -5.1950e-02,  1.3522e-01,  3.7365e-01, -2.2090e-01,\n",
              "        -2.3700e-01,  6.8155e-02,  1.4294e-01, -1.0073e-01,  1.6736e-01,\n",
              "         4.6851e-01,  9.8546e-02,  6.3974e-02, -1.8755e-01, -3.9722e-01,\n",
              "        -6.6792e-02,  3.7311e-01,  4.7436e-01,  2.0752e-01,  2.1708e-01,\n",
              "        -2.8391e-02,  1.3188e-01,  1.8706e-02, -2.0445e-01,  3.8880e-01,\n",
              "         3.5730e-01,  5.6838e-02,  5.9367e-02,  1.2732e-02,  6.9935e-02,\n",
              "        -5.4068e-01, -4.2012e-01, -2.2822e-01,  3.4508e-01, -3.7078e-01])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xqOTgbVUp1Gc"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}