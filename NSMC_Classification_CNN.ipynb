{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "NSMC_Classification_CNN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMJfMcKSlRUhLOlK3mRu1DM"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m8X6TCb-6h8v",
        "outputId": "344259e9-2871-4d45-9cc0-47da202f261f"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "shyy79L76Tlt"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n3cnoF4_zk6r",
        "outputId": "6f3e3b71-26c0-4e86-b252-1d8dbbe2a11d"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7cJn0lKa6ePc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "22f9f862-d130-4c99-f4cd-18188619d28d"
      },
      "source": [
        "!git clone https://github.com/SOMJANG/Mecab-ko-for-Google-Colab.git\n",
        "%cd Mecab-ko-for-Google-Colab\n",
        "!bash install_mecab-ko_on_colab190912.sh"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'Mecab-ko-for-Google-Colab'...\n",
            "remote: Enumerating objects: 91, done.\u001b[K\n",
            "remote: Counting objects: 100% (91/91), done.\u001b[K\n",
            "remote: Compressing objects: 100% (85/85), done.\u001b[K\n",
            "remote: Total 91 (delta 43), reused 22 (delta 6), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (91/91), done.\n",
            "/content/Mecab-ko-for-Google-Colab\n",
            "Installing konlpy.....\n",
            "Collecting konlpy\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/85/0e/f385566fec837c0b83f216b2da65db9997b35dd675e107752005b7d392b1/konlpy-0.5.2-py2.py3-none-any.whl (19.4MB)\n",
            "\u001b[K     |████████████████████████████████| 19.4MB 1.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (4.2.6)\n",
            "Requirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.7/dist-packages (from konlpy) (1.19.5)\n",
            "Collecting colorama\n",
            "  Downloading https://files.pythonhosted.org/packages/44/98/5b86278fbbf250d239ae0ecb724f8572af1c91f4a11edf4d36a206189440/colorama-0.4.4-py2.py3-none-any.whl\n",
            "Collecting beautifulsoup4==4.6.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9e/d4/10f46e5cfac773e22707237bfcd51bbffeaf0a576b0a847ec7ab15bd7ace/beautifulsoup4-4.6.0-py3-none-any.whl (86kB)\n",
            "\u001b[K     |████████████████████████████████| 92kB 14.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: tweepy>=3.7.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (3.10.0)\n",
            "Collecting JPype1>=0.7.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/98/88/f817ef1af6f794e8f11313dcd1549de833f4599abcec82746ab5ed086686/JPype1-1.3.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (448kB)\n",
            "\u001b[K     |████████████████████████████████| 450kB 30.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tweepy>=3.7.0->konlpy) (1.15.0)\n",
            "Requirement already satisfied: requests[socks]>=2.11.1 in /usr/local/lib/python3.7/dist-packages (from tweepy>=3.7.0->konlpy) (2.23.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tweepy>=3.7.0->konlpy) (1.3.0)\n",
            "Requirement already satisfied: typing-extensions; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from JPype1>=0.7.0->konlpy) (3.7.4.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2.10)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6; extra == \"socks\" in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.7.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->tweepy>=3.7.0->konlpy) (3.1.0)\n",
            "Installing collected packages: colorama, beautifulsoup4, JPype1, konlpy\n",
            "  Found existing installation: beautifulsoup4 4.6.3\n",
            "    Uninstalling beautifulsoup4-4.6.3:\n",
            "      Successfully uninstalled beautifulsoup4-4.6.3\n",
            "Successfully installed JPype1-1.3.0 beautifulsoup4-4.6.0 colorama-0.4.4 konlpy-0.5.2\n",
            "Done\n",
            "Installing mecab-0.996-ko-0.9.2.tar.gz.....\n",
            "Downloading mecab-0.996-ko-0.9.2.tar.gz.......\n",
            "from https://bitbucket.org/eunjeon/mecab-ko/downloads/mecab-0.996-ko-0.9.2.tar.gz\n",
            "--2021-06-13 04:36:30--  https://bitbucket.org/eunjeon/mecab-ko/downloads/mecab-0.996-ko-0.9.2.tar.gz\n",
            "Resolving bitbucket.org (bitbucket.org)... 104.192.141.1, 2406:da00:ff00::22c3:9b0a, 2406:da00:ff00::6b17:d1f5, ...\n",
            "Connecting to bitbucket.org (bitbucket.org)|104.192.141.1|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://bbuseruploads.s3.amazonaws.com/eunjeon/mecab-ko/downloads/mecab-0.996-ko-0.9.2.tar.gz?Signature=%2Be%2BcgOpRoI1yLTm9AfCcNcKxKoc%3D&Expires=1623560646&AWSAccessKeyId=AKIA6KOSE3BNJRRFUUX6&versionId=null&response-content-disposition=attachment%3B%20filename%3D%22mecab-0.996-ko-0.9.2.tar.gz%22&response-content-encoding=None [following]\n",
            "--2021-06-13 04:36:30--  https://bbuseruploads.s3.amazonaws.com/eunjeon/mecab-ko/downloads/mecab-0.996-ko-0.9.2.tar.gz?Signature=%2Be%2BcgOpRoI1yLTm9AfCcNcKxKoc%3D&Expires=1623560646&AWSAccessKeyId=AKIA6KOSE3BNJRRFUUX6&versionId=null&response-content-disposition=attachment%3B%20filename%3D%22mecab-0.996-ko-0.9.2.tar.gz%22&response-content-encoding=None\n",
            "Resolving bbuseruploads.s3.amazonaws.com (bbuseruploads.s3.amazonaws.com)... 52.216.153.252\n",
            "Connecting to bbuseruploads.s3.amazonaws.com (bbuseruploads.s3.amazonaws.com)|52.216.153.252|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1414979 (1.3M) [application/x-tar]\n",
            "Saving to: ‘mecab-0.996-ko-0.9.2.tar.gz’\n",
            "\n",
            "mecab-0.996-ko-0.9. 100%[===================>]   1.35M  --.-KB/s    in 0.05s   \n",
            "\n",
            "2021-06-13 04:36:30 (27.7 MB/s) - ‘mecab-0.996-ko-0.9.2.tar.gz’ saved [1414979/1414979]\n",
            "\n",
            "Done\n",
            "Unpacking mecab-0.996-ko-0.9.2.tar.gz.......\n",
            "Done\n",
            "Change Directory to mecab-0.996-ko-0.9.2.......\n",
            "installing mecab-0.996-ko-0.9.2.tar.gz........\n",
            "configure\n",
            "make\n",
            "make check\n",
            "make install\n",
            "ldconfig\n",
            "Done\n",
            "Change Directory to /content\n",
            "Downloading mecab-ko-dic-2.1.1-20180720.tar.gz.......\n",
            "from https://bitbucket.org/eunjeon/mecab-ko-dic/downloads/mecab-ko-dic-2.1.1-20180720.tar.gz\n",
            "--2021-06-13 04:37:43--  https://bitbucket.org/eunjeon/mecab-ko-dic/downloads/mecab-ko-dic-2.1.1-20180720.tar.gz\n",
            "Resolving bitbucket.org (bitbucket.org)... 104.192.141.1, 2406:da00:ff00::6b17:d1f5, 2406:da00:ff00::22c3:9b0a, ...\n",
            "Connecting to bitbucket.org (bitbucket.org)|104.192.141.1|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://bbuseruploads.s3.amazonaws.com/a4fcd83e-34f1-454e-a6ac-c242c7d434d3/downloads/b5a0c703-7b64-45ed-a2d7-180e962710b6/mecab-ko-dic-2.1.1-20180720.tar.gz?Signature=gQSYIFkt57P8beN6v3BGAc7Bf2k%3D&Expires=1623560736&AWSAccessKeyId=AKIA6KOSE3BNJRRFUUX6&versionId=tzyxc1TtnZU_zEuaaQDGN4F76hPDpyFq&response-content-disposition=attachment%3B%20filename%3D%22mecab-ko-dic-2.1.1-20180720.tar.gz%22&response-content-encoding=None [following]\n",
            "--2021-06-13 04:37:43--  https://bbuseruploads.s3.amazonaws.com/a4fcd83e-34f1-454e-a6ac-c242c7d434d3/downloads/b5a0c703-7b64-45ed-a2d7-180e962710b6/mecab-ko-dic-2.1.1-20180720.tar.gz?Signature=gQSYIFkt57P8beN6v3BGAc7Bf2k%3D&Expires=1623560736&AWSAccessKeyId=AKIA6KOSE3BNJRRFUUX6&versionId=tzyxc1TtnZU_zEuaaQDGN4F76hPDpyFq&response-content-disposition=attachment%3B%20filename%3D%22mecab-ko-dic-2.1.1-20180720.tar.gz%22&response-content-encoding=None\n",
            "Resolving bbuseruploads.s3.amazonaws.com (bbuseruploads.s3.amazonaws.com)... 52.217.64.76\n",
            "Connecting to bbuseruploads.s3.amazonaws.com (bbuseruploads.s3.amazonaws.com)|52.217.64.76|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 49775061 (47M) [application/x-tar]\n",
            "Saving to: ‘mecab-ko-dic-2.1.1-20180720.tar.gz’\n",
            "\n",
            "mecab-ko-dic-2.1.1- 100%[===================>]  47.47M   117MB/s    in 0.4s    \n",
            "\n",
            "2021-06-13 04:37:44 (117 MB/s) - ‘mecab-ko-dic-2.1.1-20180720.tar.gz’ saved [49775061/49775061]\n",
            "\n",
            "Done\n",
            "Unpacking  mecab-ko-dic-2.1.1-20180720.tar.gz.......\n",
            "Done\n",
            "Change Directory to mecab-ko-dic-2.1.1-20180720\n",
            "Done\n",
            "installing........\n",
            "configure\n",
            "make\n",
            "make install\n",
            "apt-get update\n",
            "apt-get upgrade\n",
            "apt install curl\n",
            "apt install git\n",
            "bash <(curl -s https://raw.githubusercontent.com/konlpy/konlpy/master/scripts/mecab.sh)\n",
            "Done\n",
            "Successfully Installed\n",
            "Now you can use Mecab\n",
            "from konlpy.tag import Mecab\n",
            "mecab = Mecab()\n",
            "사용자 사전 추가 방법 : https://bit.ly/3k0ZH53\n",
            "NameError: name 'Tagger' is not defined 오류 발생 시 런타임을 재실행 해주세요\n",
            "블로그에 해결 방법을 남겨주신 tana님 감사합니다.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I64YvthHBI_0"
      },
      "source": [
        "from torchtext.legacy import data\n",
        "from konlpy.tag import Mecab"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PYCwdiGnA03M",
        "outputId": "4789fbcd-fa70-48a6-d43a-b6768e643956"
      },
      "source": [
        "cd /content/drive/MyDrive/torch_example/"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/torch_example\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ONSGndtPBMyr"
      },
      "source": [
        "tokenizer = Mecab()"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dQg-1dMbLVsU",
        "outputId": "326c21a5-ae7a-4e75-e27d-9857e0160bf4"
      },
      "source": [
        "train = pd.read_csv(\"./data/nsmc/ratings_train.txt\", sep='\\t')\n",
        "test = pd.read_csv(\"./data/nsmc/ratings_test.txt\", sep='\\t')\n",
        "\n",
        "train = train.drop(columns=['id'])\n",
        "test = test.drop(columns=['id'])\n",
        "\n",
        "print(train.shape)\n",
        "print(test.shape)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(150000, 2)\n",
            "(50000, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_EL3Fhl5bDdU",
        "outputId": "ff21d35d-bbf3-4537-9337-43138e7f7446"
      },
      "source": [
        "train_data = train.dropna() #말뭉치에서 nan 값을 제거함\n",
        "test_data = test.dropna()\n",
        "\n",
        "print(train_data.shape)\n",
        "print(test_data.shape)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(149995, 2)\n",
            "(49997, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f7ATQyWmMMCF"
      },
      "source": [
        "train_data, valid_data = train_test_split(train_data, test_size=0.3, random_state=32)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CWEE8eTSMhqh",
        "outputId": "ddc98f6d-1038-4b1e-e706-4dc1a270a05a"
      },
      "source": [
        "print(len(train_data))\n",
        "print(len(valid_data))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "104996\n",
            "44999\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NU4u-h4ZBO-6"
      },
      "source": [
        "TEXT = data.Field(sequential=True, use_vocab=True, tokenize=tokenizer.morphs, lower=False, batch_first=True, fix_length=20)\n",
        "LABEL = data.LabelField(dtype = torch.float) "
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8b4ymeVtNPl_"
      },
      "source": [
        "def convert_dataset(input_data, text, label):\n",
        "    list_of_example = [data.Example.fromlist(row.tolist(), fields=[('text', text), ('label', label)])  for _, row in input_data.iterrows()]\n",
        "    dataset = data.Dataset(examples=list_of_example, fields=[('text', text), ('label', label)])\n",
        "    return dataset"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IR41A4m9OBJM"
      },
      "source": [
        "train_data = convert_dataset(train_data,TEXT,LABEL)\n",
        "valid_data = convert_dataset(valid_data, TEXT, LABEL)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e3CLzUr8DDkE"
      },
      "source": [
        "TEXT.build_vocab(train_data, max_size=10000)\n",
        "LABEL.build_vocab(train_data)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nFQaqoPnDLaE",
        "outputId": "3010d04d-8a25-4169-9c78-df290939ecbf"
      },
      "source": [
        "print('단어 집합의 크기 : {}'.format(len(TEXT.vocab)))\n",
        "print('label 의 크기 : {}'.format(len(LABEL.vocab)))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "단어 집합의 크기 : 10002\n",
            "label 의 크기 : 2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yeoY2_b4DS6E"
      },
      "source": [
        "10000개 단어 + \\<unk> + \\<pad> 토큰이 들어감\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kz5XeWKeEkwG",
        "outputId": "420e72cc-f4db-47ea-d7c8-598dc12fffa9"
      },
      "source": [
        "print(LABEL.vocab.stoi) #라벨 값이 "
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "defaultdict(None, {0: 0, 1: 1})\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NQhMoHCg0ZmN"
      },
      "source": [
        "test_data = convert_dataset(test_data, TEXT, LABEL)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9gGUTpZ2DNvz"
      },
      "source": [
        "batch_size = 5\n",
        "train_iter, valid_iter, test_iter = data.Iterator.splits((train_data, valid_data, test_data), batch_size=batch_size, sort=False, device=device)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Q8mve6nDg7_",
        "outputId": "e138ff96-b3f3-40fc-93fb-b176d3791f62"
      },
      "source": [
        "print('훈련 데이터의 미니 배치 수 : {}'.format(len(train_iter)))\n",
        "print('평가 데이터의 미니 배치 수 : {}'.format(len(valid_iter)))\n",
        "print('테스트 데이터의 미니 배치 수 : {}'.format(len(test_iter)))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "훈련 데이터의 미니 배치 수 : 21000\n",
            "평가 데이터의 미니 배치 수 : 9000\n",
            "테스트 데이터의 미니 배치 수 : 10000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "06D_jCqWe0Zp"
      },
      "source": [
        "text를 cnn으로 돌릴때, conv2d와 conv1d로 나눠서 돌릴 수 있다.\n",
        "두 가지 모두 작성해보도록 한다. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cz9I8uT9Jz2d"
      },
      "source": [
        "CNN을 2d로 볼 때, 이미지와 다르게 text는 input_chanel 이 1이다. (이미지는 3임) 왜냐면 이미지는 R,G,B로 3개이기 때문이다.\n",
        "그 외에는 별다를게 없다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O70kcjWUKJCE"
      },
      "source": [
        "CNN을 1d 로 볼 때, input_chanel은 embed dim이다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L15OceFfFBbi"
      },
      "source": [
        "class CNN2D(nn.Module):\n",
        "  def __init__(self,  vocab_size, embedding_dim, n_filters, filter_sizes, output_dim, \n",
        "                 dropout, pad_idx):\n",
        "    super().__init__()\n",
        "    self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=pad_idx)\n",
        "\n",
        "    self.conv1 = nn.Conv2d(in_channels=1, out_channels=n_filters, kernel_size=(filter_sizes[0], embedding_dim))\n",
        "    self.conv2 = nn.Conv2d(in_channels=1, out_channels=n_filters, kernel_size=(filter_sizes[1], embedding_dim))\n",
        "    self.conv3 = nn.Conv2d(in_channels=1, out_channels=n_filters, kernel_size=(filter_sizes[2], embedding_dim))\n",
        "    \n",
        "    self.fc = nn.Linear(n_filters * len(filter_sizes), output_dim)\n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "  \n",
        "  def forward(self, x):\n",
        "    # x : batch x seq len\n",
        "    embedded = self.embedding(x)\n",
        "    # embedded = batch x seq len x embed dim\n",
        "\n",
        "    embedded = embedded.unsqueeze(1)\n",
        "    # embedded = batch x 1 x seq len x embed dim\n",
        "\n",
        "    out_conv1 = self.conv1(embedded)\n",
        "    #out_conv1 = batch x feature map x (seq len - filter_size[0] + 1) x 1\n",
        "    out_conv1 = F.relu(out_conv1.squeeze(3))\n",
        "    # out_conv1 = batch x feature map x (seq len - filter size[0] + 1)\n",
        "\n",
        "    out_conv2 = F.relu(self.conv2(embedded).squeeze(3))\n",
        "    out_conv3 = F.relu(self.conv3(embedded).squeeze(3))\n",
        "\n",
        "    pooled_1 = F.max_pool1d(out_conv1, out_conv1.shape[2]).squeeze(2)\n",
        "    pooled_2 = F.max_pool1d(out_conv2, out_conv2.shape[2]).squeeze(2)\n",
        "    pooled_3 = F.max_pool1d(out_conv3, out_conv3.shape[2]).squeeze(2)\n",
        "    # pooled : batch x feature map\n",
        "\n",
        "    output = self.fc(self.dropout(torch.cat((pooled_1, pooled_2, pooled_3), dim=1)))\n",
        "\n",
        "    return output\n",
        "    "
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ORUyOAYuahxf"
      },
      "source": [
        "#위의 코드를 nn.ModuleList를 활용해서 작성한 코드입니다.\n",
        "class CNN2D(nn.Module):\n",
        "  def __init__(self,  vocab_size, embedding_dim, n_filters, filter_sizes, output_dim, \n",
        "                 dropout, pad_idx):\n",
        "    super().__init__()\n",
        "    self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=pad_idx)\n",
        "\n",
        "    self.conv = nn.ModuleList([nn.Conv2d(in_channels=1, out_channels=n_filters, kernel_size=(filtersize, embedding_dim)) \\\n",
        "                               for filtersize in filter_sizes])\n",
        "    \n",
        "    self.fc = nn.Linear(n_filters * len(filter_sizes), output_dim)\n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "  \n",
        "  def forward(self, x):\n",
        "    # x : batch x seq len\n",
        "    embedded = self.embedding(x)\n",
        "    # embedded = batch x seq len x embed dim\n",
        "\n",
        "    embedded = embedded.unsqueeze(1)\n",
        "    # embedded = batch x 1 x seq len x embed dim\n",
        "\n",
        "    conv_out = [F.relu(conv(embedded).squeeze(3)) for conv in self.conv]\n",
        "    # conv_out : batch x feature map x (sent len - filter_size[n] + 1)\n",
        "\n",
        "    pooled = [F.max_pool1d(conv, conv.shape[2]).squeeze(2) for conv in conv_out]\n",
        "    # pooled : batch x feature map\n",
        "\n",
        "    output = self.fc(self.dropout(torch.cat((pooled[0], pooled[1], pooled[2]), dim=1)))\n",
        "\n",
        "    return output"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QqD-Bk0-dJLU"
      },
      "source": [
        "class CNN1D(nn.Module):\n",
        "  def __init__(self, vocab_size, embedding_dim, n_filters, filter_sizes, output_dim, \n",
        "                 dropout, pad_idx):\n",
        "    self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=pad_idx)\n",
        "\n",
        "    self.conv = nn.ModuleList([ nn.Conv1d(in_channels=embedding_dim, out_channels=n_filters, kernel_size=filter)\\\n",
        "                               for filter in filter_sizes])\n",
        "\n",
        "    self.fc = nn.Linear( n_filters * len(filter_size), output_dim)\n",
        "    self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "  def forward(self, x):\n",
        "    embedded = self.embedding(x)\n",
        "    #embedded : batch x seq len x embed dim\n",
        "\n",
        "    embedded = embedded.premute(0,2,1)\n",
        "    #embedded : batch x embed dim x seq len\n",
        "\n",
        "    conv_out = [F.relu(conv(embedded)) for conv in self.conv] \n",
        "    #conv_out : batch x feature map x (sent len - filter_size[n] + 1)\n",
        "\n",
        "    pooled = [F.max_pool1d(conv, conv.shape[2]).squeeze(2) for conv in conv_out]\n",
        "    # pooled : batch x feature map\n",
        "\n",
        "    output = self.fc(self.dropout(torch.cat(pooled, dim =1)))\n",
        "\n",
        "    return output"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hH0XYn65xqt5"
      },
      "source": [
        "def binary_accuracy(prediction, target):\n",
        "  '''\n",
        "from https://github.com/bentrevett/pytorch-sentiment-analysis/blob/master/1%20-%20Simple%20Sentiment%20Analysis.ipynb\n",
        "  '''\n",
        "  # round predictions to the closest integer (0 or 1)\n",
        "  rounded_preds = torch.round(torch.sigmoid(prediction))\n",
        "  \n",
        "  #convert into float for division\n",
        "  correct = (rounded_preds == target).float()\n",
        "\n",
        "  # rounded_preds = [ 1   0   0   1   1   1   0   1   1   1]\n",
        "  # targets       = [ 1   0   1   1   1   1   0   1   1   0]\n",
        "  # correct       = [1.0 1.0 0.0 1.0 1.0 1.0 1.0 1.0 1.0 0.0]\n",
        "  acc = correct.sum() / len(correct)\n",
        "  return acc"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9MgSjQr3sa5i"
      },
      "source": [
        "def train(model, train_iter):\n",
        "  model.train()\n",
        "\n",
        "  epoch_loss, epoch_acc = 0, 0\n",
        "  for batch in train_iter:\n",
        "    optimizer.zero_grad()\n",
        "    x, y = batch.text.to(device), batch.label.to(device)\n",
        "    y_hat = model(x).squeeze(1)\n",
        "\n",
        "    loss = criterion(y_hat, y)\n",
        "    acc = binary_accuracy(y_hat, y)\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    epoch_loss += loss.item()\n",
        "    epoch_acc += acc.item()\n",
        "\n",
        "  return epoch_loss / len(train_iter), epoch_acc / len(train_iter)\n"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZkuKVVyCzTF8"
      },
      "source": [
        "def evaluate(model, valid_iter):\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "    eval_loss, eval_acc = 0, 0\n",
        "    for batch in valid_iter:\n",
        "      x,y = batch.text.to(device), batch.label.to(device)\n",
        "      y_hat = model(x).squeeze(1)\n",
        "      \n",
        "      loss = criterion(y_hat, y)\n",
        "      acc = binary_accuracy(y_hat, y)\n",
        "\n",
        "      eval_loss += loss.item()\n",
        "      eval_acc += acc.item()\n",
        "      \n",
        "  return eval_loss / len(valid_iter), eval_acc / len(valid_iter)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ss8RYLuN3QWN"
      },
      "source": [
        "def inference(model, test_iter):\n",
        "  model.eval()\n",
        "  with torch.no_grad():\n",
        "    test_loss, test_acc = 0, 0\n",
        "    for batch in test_iter:\n",
        "      x, y = batch.text.to(device), batch.label.to(device)\n",
        "      y_hat = model(x).squeeze(1)\n",
        "\n",
        "      loss = criterion(y_hat, y)\n",
        "      acc = binary_accuracy(y_hat, y)\n",
        "      \n",
        "      test_loss += loss.item()\n",
        "      test_acc += acc.item()\n",
        "\n",
        "  return test_loss / len(test_iter), test_acc / len(test_iter)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ilZJ-N2M1dcD",
        "outputId": "8f440619-c41f-441b-8902-8f23bbd3cc20"
      },
      "source": [
        "#  vocab_size, embedding_dim, n_filters, filter_sizes, output_dim, dropout, pad_idx\n",
        "PAD_IDX = TEXT.vocab.stoi[TEXT.pad_token]\n",
        "\n",
        "model = CNN2D(len(TEXT.vocab), 128, 100, [3,4,5], 1, 0.2, PAD_IDX)\n",
        "model.to(device)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "criterion.to(device)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BCEWithLogitsLoss()"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DShy6pep2BIO",
        "outputId": "5c932abe-773f-40fc-9380-4cdd0c99a4e9"
      },
      "source": [
        "best_val_loss = float('inf')\n",
        "for _epoch in range(1,6): # 5 epoch\n",
        "  train_loss, train_acc = train(model, train_iter)\n",
        "  valid_loss, valid_acc = evaluate(model, valid_iter)\n",
        "  print(\"[Epoch: %d] train loss : %5.2f | train accuracy : %5.2f\" % (_epoch, train_loss, train_acc))\n",
        "  print(\"[Epoch: %d] val loss : %5.2f | val accuracy : %5.2f\" % (_epoch, valid_loss, valid_acc))\n",
        "\n",
        "    # 검증 오차가 가장 적은 최적의 모델을 저장\n",
        "  if valid_loss < best_val_loss:\n",
        "    best_val_loss = valid_loss"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[Epoch: 1] train loss :  0.46 | train accuracy :  0.78\n",
            "[Epoch: 1] val loss :  0.39 | val accuracy :  0.83\n",
            "[Epoch: 2] train loss :  0.37 | train accuracy :  0.84\n",
            "[Epoch: 2] val loss :  0.38 | val accuracy :  0.84\n",
            "[Epoch: 3] train loss :  0.32 | train accuracy :  0.87\n",
            "[Epoch: 3] val loss :  0.39 | val accuracy :  0.83\n",
            "[Epoch: 4] train loss :  0.27 | train accuracy :  0.89\n",
            "[Epoch: 4] val loss :  0.43 | val accuracy :  0.83\n",
            "[Epoch: 5] train loss :  0.23 | train accuracy :  0.91\n",
            "[Epoch: 5] val loss :  0.50 | val accuracy :  0.83\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZP8Lqf7n5CgO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a1d64d1a-7671-40a2-fe89-525a0eeae557"
      },
      "source": [
        "test_loss, test_acc = inference(model, test_iter)\n",
        "print('Test Loss: %5.2f | Test Acc: %5.2f '%(test_loss, test_acc*100))"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Loss:  0.49 | Test Acc: 82.58 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aFeqcwhpeIoV"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0yqmiLYRgVfO"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}